{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  [7608772.5]\n",
      "loss:  [5352850.0]\n",
      "loss:  [5350043.5]\n",
      "loss:  [5347918.5]\n",
      "loss:  [5346300.5]\n",
      "loss:  [5345061.5]\n",
      "loss:  [5344105.5]\n",
      "loss:  [5343361.0]\n",
      "loss:  [5342774.5]\n",
      "loss:  [5342306.5]\n",
      "loss:  [5341925.5]\n",
      "loss:  [5341611.5]\n",
      "loss:  [5341345.0]\n",
      "loss:  [5341115.5]\n",
      "loss:  [5340913.0]\n",
      "loss:  [5340733.0]\n",
      "loss:  [5340566.5]\n",
      "loss:  [5340413.5]\n",
      "loss:  [5340267.5]\n",
      "loss:  [5340128.0]\n",
      "loss:  [5339993.0]\n",
      "loss:  [5339860.5]\n",
      "loss:  [5339733.5]\n",
      "loss:  [5339606.0]\n",
      "loss:  [5339481.5]\n",
      "loss:  [5339358.0]\n",
      "loss:  [5339235.0]\n",
      "loss:  [5339112.0]\n",
      "loss:  [5338989.5]\n",
      "loss:  [5338869.0]\n",
      "loss:  [5338747.0]\n",
      "loss:  [5338625.0]\n",
      "loss:  [5338504.5]\n",
      "loss:  [5338384.0]\n",
      "loss:  [5338262.0]\n",
      "loss:  [5338141.0]\n",
      "loss:  [5338022.0]\n",
      "loss:  [5337900.5]\n",
      "loss:  [5337780.0]\n",
      "loss:  [5337661.0]\n",
      "loss:  [5337538.0]\n",
      "loss:  [5337418.0]\n",
      "loss:  [5337297.0]\n",
      "loss:  [5337177.5]\n",
      "loss:  [5337056.5]\n",
      "loss:  [5336936.0]\n",
      "loss:  [5336815.5]\n",
      "loss:  [5336696.0]\n",
      "loss:  [5336575.0]\n",
      "loss:  [5336455.0]\n",
      "loss:  [5336334.0]\n",
      "loss:  [5336213.0]\n",
      "loss:  [5336093.0]\n",
      "loss:  [5335973.0]\n",
      "loss:  [5335852.5]\n",
      "loss:  [5335732.5]\n",
      "loss:  [5335611.5]\n",
      "loss:  [5335491.5]\n",
      "loss:  [5335370.5]\n",
      "loss:  [5335250.0]\n",
      "loss:  [5335129.5]\n",
      "loss:  [5335009.0]\n",
      "loss:  [5334888.5]\n",
      "loss:  [5334768.5]\n",
      "loss:  [5334647.5]\n",
      "loss:  [5334526.5]\n",
      "loss:  [5334409.0]\n",
      "loss:  [5334287.0]\n",
      "loss:  [5334167.0]\n",
      "loss:  [5334047.5]\n",
      "loss:  [5333926.5]\n",
      "loss:  [5333806.0]\n",
      "loss:  [5333686.0]\n",
      "loss:  [5333565.0]\n",
      "loss:  [5333446.0]\n",
      "loss:  [5333325.5]\n",
      "loss:  [5333205.0]\n",
      "loss:  [5333085.0]\n",
      "loss:  [5332965.0]\n",
      "loss:  [5332844.5]\n",
      "loss:  [5332724.0]\n",
      "loss:  [5332603.5]\n",
      "loss:  [5332484.5]\n",
      "loss:  [5332363.5]\n",
      "loss:  [5332243.5]\n",
      "loss:  [5332123.5]\n",
      "loss:  [5332002.5]\n",
      "loss:  [5331883.5]\n",
      "loss:  [5331763.0]\n",
      "loss:  [5331642.0]\n",
      "loss:  [5331523.5]\n",
      "loss:  [5331403.5]\n",
      "loss:  [5331282.5]\n",
      "loss:  [5331161.5]\n",
      "loss:  [5331042.0]\n",
      "loss:  [5330922.5]\n",
      "loss:  [5330802.5]\n",
      "loss:  [5330682.0]\n",
      "loss:  [5330563.0]\n",
      "loss:  [5330442.5]\n",
      "loss:  [5330322.0]\n",
      "loss:  [5330201.0]\n",
      "loss:  [5330082.0]\n",
      "loss:  [5329962.0]\n",
      "loss:  [5329841.5]\n",
      "loss:  [5329722.0]\n",
      "loss:  [5329601.0]\n",
      "loss:  [5329482.5]\n",
      "loss:  [5329361.5]\n",
      "loss:  [5329242.0]\n",
      "loss:  [5329122.0]\n",
      "loss:  [5329002.5]\n",
      "loss:  [5328881.5]\n",
      "loss:  [5328762.5]\n",
      "loss:  [5328642.5]\n",
      "loss:  [5328522.5]\n",
      "loss:  [5328403.0]\n",
      "loss:  [5328283.0]\n",
      "loss:  [5328163.0]\n",
      "loss:  [5328043.0]\n",
      "loss:  [5327924.5]\n",
      "loss:  [5327803.0]\n",
      "loss:  [5327684.0]\n",
      "loss:  [5327564.5]\n",
      "loss:  [5327444.5]\n",
      "loss:  [5327324.5]\n",
      "loss:  [5327204.5]\n",
      "loss:  [5327085.5]\n",
      "loss:  [5326963.5]\n",
      "loss:  [5326845.0]\n",
      "loss:  [5326726.0]\n",
      "loss:  [5326606.0]\n",
      "loss:  [5326485.5]\n",
      "loss:  [5326366.0]\n",
      "loss:  [5326246.0]\n",
      "loss:  [5326126.5]\n",
      "loss:  [5326006.5]\n",
      "loss:  [5325887.5]\n",
      "loss:  [5325768.0]\n",
      "loss:  [5325647.0]\n",
      "loss:  [5325528.0]\n",
      "loss:  [5325409.0]\n",
      "loss:  [5325289.0]\n",
      "loss:  [5325169.5]\n",
      "loss:  [5325049.5]\n",
      "loss:  [5324930.5]\n",
      "loss:  [5324808.0]\n",
      "loss:  [5324690.0]\n",
      "loss:  [5324570.0]\n",
      "loss:  [5324450.0]\n",
      "loss:  [5324332.5]\n",
      "loss:  [5324212.5]\n",
      "loss:  [5324093.0]\n",
      "loss:  [5323973.0]\n",
      "loss:  [5323852.5]\n",
      "loss:  [5323733.5]\n",
      "loss:  [5323614.5]\n",
      "loss:  [5323496.0]\n",
      "loss:  [5323375.5]\n",
      "loss:  [5323255.5]\n",
      "loss:  [5323136.0]\n",
      "loss:  [5323017.0]\n",
      "loss:  [5322898.0]\n",
      "loss:  [5322777.5]\n",
      "loss:  [5322659.0]\n",
      "loss:  [5322539.5]\n",
      "loss:  [5322419.5]\n",
      "loss:  [5322299.0]\n",
      "loss:  [5322180.0]\n",
      "loss:  [5322059.5]\n",
      "loss:  [5321942.0]\n",
      "loss:  [5321822.5]\n",
      "loss:  [5321702.0]\n",
      "loss:  [5321584.0]\n",
      "loss:  [5321463.5]\n",
      "loss:  [5321343.5]\n",
      "loss:  [5321225.0]\n",
      "loss:  [5321105.5]\n",
      "loss:  [5320986.5]\n",
      "loss:  [5320866.5]\n",
      "loss:  [5320747.0]\n",
      "loss:  [5320628.0]\n",
      "loss:  [5320509.5]\n",
      "loss:  [5320389.5]\n",
      "loss:  [5320270.0]\n",
      "loss:  [5320152.0]\n",
      "loss:  [5320033.0]\n",
      "loss:  [5319912.0]\n",
      "loss:  [5319793.5]\n",
      "loss:  [5319673.0]\n",
      "loss:  [5319554.5]\n",
      "loss:  [5319435.5]\n",
      "loss:  [5319316.5]\n",
      "loss:  [5319197.0]\n",
      "loss:  [5319077.0]\n",
      "loss:  [5318958.5]\n",
      "loss:  [5318839.0]\n",
      "loss:  [5318719.0]\n",
      "loss:  [5318601.5]\n",
      "loss:  [5318481.5]\n",
      "[[ 320.61459351]]\n",
      "[[ 267.9335022]]\n",
      "[[ 356.00912476]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# initialize variables/model parameters\n",
    "W = tf.Variable(tf.zeros([2,1]), name='weights')\n",
    "b = tf.Variable(0., name='bias')\n",
    "\n",
    "def inference(X):\n",
    "    # compute inference model over data X and return the result\n",
    "    return tf.matmul(X, W) + b\n",
    "    \n",
    "def loss(X, Y):\n",
    "    # compute loss over training data X and expected outputs Y\n",
    "    Y_predicted = inference(X)\n",
    "    return tf.reduce_sum(tf.squared_difference(Y, Y_predicted))\n",
    "    \n",
    "def inputs():\n",
    "    # read/generate input training data X and expected outputs Y\n",
    "    weight_age = [[84, 46], [73, 20], [65, 52], [70,30], [76,57], [69, 25], [63, 28], \n",
    "                  [72,36], [79, 57], [75, 44], [27,24], [89, 31], [65, 52], [57, 23], [59, 60],\n",
    "                 [69, 48], [60, 34], [79,51], [75, 50], [82, 34], [59, 46], [67, 23], [85, 37],\n",
    "                 [55, 40], [63, 30]]\n",
    "    blood_fat_content = [354, 190, 405, 263, 451, 302, 288, 385, 402, 365, 209, 290,\n",
    "                        346, 254, 395, 434, 220, 374, 308, 220, 311, 181, 274, 303, 244]\n",
    "    return tf.to_float(weight_age), tf.to_float(blood_fat_content)\n",
    "\n",
    "def train(total_loss):\n",
    "    learning_rate = 0.0000001\n",
    "    return tf.train.GradientDescentOptimizer(learning_rate).minimize(total_loss)\n",
    "\n",
    "def evaluate(sess, X, Y):\n",
    "    # evaluate the resulting trained model\n",
    "    print sess.run(inference([[80., 25.]])) # ~ 303\n",
    "    print sess.run(inference([[65., 25.]])) # ~ 256\n",
    "    print sess.run(inference([[79., 51.]]))\n",
    "\n",
    "# Create a saver.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Launch the graph in a session, setup boilerplate\n",
    "with tf.Session() as sess:\n",
    "    tf.initialize_all_variables().run()\n",
    "    X, Y = inputs()\n",
    "    total_loss = loss(X, Y)\n",
    "    train_op = train(total_loss)\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    initial_step = 0\n",
    "    # verify if we don't have a checkpoint saved already\n",
    "#     ckpt = tf.train.get_checkpoint_state(os.path.dirname(__file__))\n",
    "#     if ckpt and ckpt.model_checkpoint_path:\n",
    "#         # Restores from checkpoint\n",
    "#         saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "#         initial_step = int(ckpt.model_checkpoint_path.rsplit('-', l)[1])\n",
    "    \n",
    "    # actual training loop\n",
    "    training_steps = 1000\n",
    "    for step in range(initial_step, training_steps):\n",
    "        sess.run([train_op])\n",
    "        # for debugging and learning purposes, see how the loss gets decremented thru training steps\n",
    "        if step % 10 == 0:\n",
    "            print \"loss: \", sess.run([total_loss])\n",
    "            \n",
    "        if step % 1000 == 0:\n",
    "            saver.save(sess, 'my-model', global_step=step)\n",
    "    \n",
    "    # evaluation...\n",
    "    evaluate(sess, X, Y)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    saver.save(sess, 'my-model', global_step=training_steps)\n",
    "    sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
