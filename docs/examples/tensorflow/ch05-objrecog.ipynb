{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://github.com/backstopmedia/tensorflowbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'DecodeRaw:0' shape=(?,) dtype=uint8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "    tf.train.match_filenames_once('~/pooh/poohdrop/mldata/tf_inteligence/output/training-images/*.tfrecords'))\n",
    "reader = tf.TFRecordReader()\n",
    "_, serialized = reader.read(filename_queue)\n",
    "features = tf.parse_single_example(\n",
    "    serialized,\n",
    "    features={\n",
    "        'label': tf.FixedLenFeature([], tf.string),\n",
    "        'image': tf.FixedLenFeature([], tf.string),\n",
    "    })\n",
    "record_image = tf.decode_raw(features['image'], tf.uint8)\n",
    "record_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'shuffle_batch:0' shape=(3, 250, 151, 1) dtype=uint8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = tf.reshape(record_image, [250, 151, 1])\n",
    "label = tf.cast(features['label'], tf.string)\n",
    "min_after_dequeue = 10\n",
    "batch_size = 3\n",
    "capacity = min_after_dequeue + 3 * batch_size\n",
    "image_batch, label_batch = tf.train.shuffle_batch(\n",
    "    [image, label], batch_size=batch_size, capacity=capacity,\n",
    "    min_after_dequeue=min_after_dequeue)\n",
    "image_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Converting the images to a float of [0,1) to match the expected input to convolution2d\n",
    "float_image_batch = tf.image.convert_image_dtype(image_batch, tf.float32)\n",
    "conv2d_layer_one = tf.contrib.layers.convolution2d(\n",
    "    float_image_batch,\n",
    "    num_outputs=32,\n",
    "    kernel_size=(5,5),\n",
    "    activation_fn=tf.nn.relu,\n",
    "    weights_initializer=tf.random_normal_initializer(),\n",
    "    stride=(2,2),\n",
    "    trainable=True)\n",
    "pool_layer_one = tf.nn.max_pool(conv2d_layer_one,\n",
    "                                ksize=[1,2,2,1],\n",
    "                               strides=[1,2,2,1],\n",
    "                               padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(3), Dimension(125), Dimension(76), Dimension(32)]),\n",
       " TensorShape([Dimension(3), Dimension(63), Dimension(38), Dimension(32)]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note, the first and last dimension of the convolution output hasn't changed but the\n",
    "# middle two dimensions have\n",
    "conv2d_layer_one.get_shape(), pool_layer_one.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([Dimension(3), Dimension(63), Dimension(38), Dimension(64)]),\n",
       " TensorShape([Dimension(3), Dimension(32), Dimension(19), Dimension(64)]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d_layer_two = tf.contrib.layers.convolution2d(\n",
    "    pool_layer_one,\n",
    "    num_outputs=64,\n",
    "    kernel_size=(5,5),\n",
    "    activation_fn=tf.nn.relu,\n",
    "    weights_initializer=tf.random_normal_initializer(),\n",
    "    stride=(1,1),\n",
    "    trainable=True)\n",
    "pool_layer_two = tf.nn.max_pool(conv2d_layer_two,\n",
    "                               ksize=[1,2,2,1],\n",
    "                               strides=[1,2,2,1],\n",
    "                               padding='SAME')\n",
    "conv2d_layer_two.get_shape(), pool_layer_two.get_shape()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(3), Dimension(38912)])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_layer_two = tf.reshape(\n",
    "    pool_layer_two,\n",
    "    [batch_size, -1])\n",
    "flattened_layer_two.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.Tensor"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_layer_three = tf.contrib.layers.fully_connected(\n",
    "    flattened_layer_two,\n",
    "    512,\n",
    "    weights_initializer=lambda i, dtype, partition_info=None:tf.truncated_normal([38912, 512], stddev=0.1),\n",
    "    activation_fn=tf.nn.relu)\n",
    "hidden_layer_three = tf.nn.dropout(hidden_layer_three, 0.1)\n",
    "\n",
    "final_fully_connected = tf.contrib.layers.fully_connected(\n",
    "    hidden_layer_three,\n",
    "    120,\n",
    "    weights_initializer=lambda i, dtype, partition_info=None: tf.truncated_normal([512, 120], stddev=0.1))\n",
    "\n",
    "import glob\n",
    "labels = list(map(lambda c: c.split(\"/\")[-1], glob.glob(\"/Users/user/Dropbox/poohdrop/mldata/data-tf_inteligence/imagenet-dogs/*\")))\n",
    "labels[:10]\n",
    "train_labels = tf.map_fn(lambda l: tf.where(tf.equal(labels, l))[0,0:1][0], label_batch, dtype=tf.int64)\n",
    "\n",
    "train_labels[:10]\n",
    "type(label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup-only-ignore\n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=final_fully_connected, labels=train_labels))\n",
    "batch = tf.Variable(0)\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    0.01,\n",
    "    batch * 3,\n",
    "    120,\n",
    "    0.95,\n",
    "    staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(\n",
    "    learning_rate, 0.9).minimize(\n",
    "    loss, global_step=batch)\n",
    "train_prediction = tf.nn.softmax(final_fully_connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
